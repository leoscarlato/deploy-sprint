{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivô\n",
    "### Modelo de classificação para verificar a se um cliente vai ou não cancelar o serviço no próximo mês\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo os dados temporais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agosto = pd.read_csv('../data/Agosto/Ana Health_Tabela Modelo Previsão Churn - Tabela até 08_23.csv', skiprows=1)\n",
    "df_julho = pd.read_csv('../data/Julho/Ana Health_Tabela Modelo Previsão Churn - Tabela até 07_23.csv', skiprows=1)\n",
    "df_junho = pd.read_csv('../data/Junho/Ana Health_Tabela Modelo Previsão Churn - Tabela até 06_23.csv', skiprows=1)\n",
    "df_novembro = pd.read_csv('../data/Novembro/Ana Health_Tabela Modelo Previsão Churn - Tabela Geral.csv', skiprows=1)\n",
    "df_outubro = pd.read_csv('../data/Outubro/Ana Health_Tabela Modelo Previsão Churn - Tabela até 10_23.csv', skiprows=1)\n",
    "df_setembro = pd.read_csv('../data/Setembro/Ana Health_Tabela Modelo Previsão Churn - Tabela até 09_23.csv', skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo o tratamento de cada um dos datasets via script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import script_dataframe\n",
    "import importlib\n",
    "\n",
    "importlib.reload(script_dataframe)\n",
    "tratamento = script_dataframe.tratamento\n",
    "\n",
    "df_agosto = tratamento(df_agosto)\n",
    "df_julho = tratamento(df_julho)\n",
    "df_junho = tratamento(df_junho)\n",
    "df_novembro = tratamento(df_novembro)\n",
    "df_outubro = tratamento(df_outubro)\n",
    "df_setembro = tratamento(df_setembro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo a função para, dado um mês, retornar o dataset do mês seguinte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prox_status(df1, df2):\n",
    "    df2_novo = df2[df2['id_person'].isin(df1['id_person'].values)]\n",
    "    return pd.merge(df1,df2_novo[['id_person','status']],on='id_person', how='left',suffixes=['','_prox_mes'])\n",
    "\n",
    "df_junho = prox_status(df_junho, df_julho)\n",
    "df_julho = prox_status(df_julho, df_agosto)\n",
    "df_agosto = prox_status(df_agosto, df_setembro)\n",
    "df_setembro = prox_status(df_setembro, df_outubro)\n",
    "df_outubro  = prox_status(df_outubro, df_novembro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenando os datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4680 entries, 0 to 1022\n",
      "Data columns (total 54 columns):\n",
      " #   Column                                      Non-Null Count  Dtype         \n",
      "---  ------                                      --------------  -----         \n",
      " 0   id_person                                   4680 non-null   int64         \n",
      " 1   birthdate                                   4675 non-null   float64       \n",
      " 2   id_gender                                   4662 non-null   float64       \n",
      " 3   id_marrital_status                          4670 non-null   float64       \n",
      " 4   id_health_plan                              2204 non-null   float64       \n",
      " 5   contract_start_date                         4680 non-null   datetime64[ns]\n",
      " 6   contract_end_date                           2292 non-null   datetime64[ns]\n",
      " 7   id_continuity_pf                            1687 non-null   float64       \n",
      " 8   Canal de Preferência                        1473 non-null   float64       \n",
      " 9   notes_count                                 4680 non-null   int64         \n",
      " 10  done_activities_count                       4680 non-null   int64         \n",
      " 11  status                                      4680 non-null   object        \n",
      " 12  start_of_service                            4680 non-null   float64       \n",
      " 13  lost_time                                   2169 non-null   float64       \n",
      " 14  lost_reason                                 2292 non-null   object        \n",
      " 15  add_time                                    4502 non-null   float64       \n",
      " 16  id_label                                    389 non-null    float64       \n",
      " 17  won_time                                    2890 non-null   float64       \n",
      " 18  lost_time.1                                 1293 non-null   float64       \n",
      " 19  lost_reason.1                               1293 non-null   object        \n",
      " 20  Qde Todos Atendimentos                      4680 non-null   int64         \n",
      " 21  Faltas Todos Atendimento                    4680 non-null   int64         \n",
      " 22  Qde Atendimento Médico                      801 non-null    float64       \n",
      " 23  Faltas Atendimento Médico                   801 non-null    float64       \n",
      " 24  Qde Atendimentos Acolhimento                2744 non-null   float64       \n",
      " 25  Faltas Acolhimento                          2744 non-null   float64       \n",
      " 26  Qde Psicoterapia                            1797 non-null   float64       \n",
      " 27  Faltas Psicoterapia                         587 non-null    object        \n",
      " 28  Físico                                      3562 non-null   float64       \n",
      " 29  Psicológico                                 3562 non-null   float64       \n",
      " 30  Social                                      3562 non-null   float64       \n",
      " 31  Ambiental                                   3562 non-null   float64       \n",
      " 32  Problemas Abertos                           2402 non-null   object        \n",
      " 33  Mensagens Inbound                           4367 non-null   float64       \n",
      " 34  Mensagens Outbound                          4606 non-null   float64       \n",
      " 35  Ligações Inbound                            430 non-null    float64       \n",
      " 36  Data Última Ligações Inbound                430 non-null    object        \n",
      " 37  Ligações Outbound                           2271 non-null   float64       \n",
      " 38  Data Última Ligações Outbound               2271 non-null   object        \n",
      " 39  Qde Total de Faturas                        880 non-null    float64       \n",
      " 40  Qde Total de Tentativas de Cobrança         878 non-null    float64       \n",
      " 41  Método de Pagamento                         880 non-null    object        \n",
      " 42  Valor Médio da Mensalidade                  880 non-null    float64       \n",
      " 43  Qde Total de Faturas Pagas após Vencimento  880 non-null    float64       \n",
      " 44  Qde Total de Faturas Inadimpletes           880 non-null    float64       \n",
      " 45  Valor Total Inadimplência                   880 non-null    float64       \n",
      " 46  Qde Perfis de Pagamento Inativos            0 non-null      float64       \n",
      " 47  Tempo até Sair                              2292 non-null   float64       \n",
      " 48  Tem Problema em Aberto                      4680 non-null   int64         \n",
      " 49  Tempo Última Mensagem Inbound               4367 non-null   float64       \n",
      " 50  Tempo Última Mensagem Outbound              4606 non-null   float64       \n",
      " 51  Quem Enviou Última Mensagem                 4680 non-null   object        \n",
      " 52  status_prox_mes                             4680 non-null   object        \n",
      " 53  Target                                      4680 non-null   bool          \n",
      "dtypes: bool(1), datetime64[ns](2), float64(35), int64(6), object(10)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_total = pd.concat([df_junho, df_julho, df_agosto, df_setembro, df_outubro])\n",
    "\n",
    "df_total['Target'] = df_total['status_prox_mes'] == 'won'\n",
    "\n",
    "df_total['Target'].value_counts()\n",
    "df_total.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando DataFrames - \n",
    "\n",
    "Temos dois dataframes que pretendemos utilizar. O primeiro, e principal, é referente a análise de quem sai no próximo mës. O segundo, é uma tentativa de prever quanto tempo até o usuário sair. \n",
    "\n",
    "### DataSet 1 - Saída de Clientes no Próximo Mës \n",
    "- Nele, temos uma coluna de ***target*** que é binária (valores verdadeiros indicam que a pessoa saiu no próxima mës). As colunas que contemplamos tem relação com o perfil do cliente, como idade, sexo, estado civil, etc. A maioria dos dados já passaram pelo script_dataframe (e a função `tratamento`) para adição de colunas novas, tratamento de datas e criação de dummies.\n",
    "\n",
    "### DataSet 2 - Tempo até o Cliente Sair\n",
    "- Processo de criação foi parecida com o anterior, mas aqui temos uma coluna de ***target*** que é contínua (valores indicam quantos dias até o cliente sair). As colunas que contemplamos tem relação com o perfil do cliente, como idade, sexo, estado civil, etc. A maioria dos dados já passaram pelo script_dataframe (e a função `tratamento`) para adição de colunas novas, tratamento de datas e criação de dummies. A diferença é que contemplamos a colunas de faltas de atendimentos e consultas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_category(x,qtd_itens,lista_itens):\n",
    "   for i in range(qtd_itens):\n",
    "      if x == lista_itens[i]:\n",
    "         return str(x)\n",
    "   return 'Outros'\n",
    "   \n",
    "colunas_dropadas = ['id_person','contract_start_date','contract_end_date','id_continuity_pf','Canal de Preferência','status','lost_time','add_time','id_label','won_time','lost_time.1','lost_reason','lost_reason.1',\\\n",
    "                    'Qde Atendimento Médico','Faltas Atendimento Médico',\t'Qde Atendimentos Acolhimento',\t'Faltas Acolhimento',\t'Qde Psicoterapia',\t'Faltas Psicoterapia','Data Última Ligações Outbound',\\\n",
    "                     'Data Última Ligações Inbound','Qde Total de Faturas Pagas após Vencimento','Qde Perfis de Pagamento Inativos','Tempo até Sair', 'Valor Médio da Mensalidade', 'status_prox_mes', 'Qde Total de Faturas','Problemas Abertos']\n",
    "\n",
    "\n",
    "colunas_dropadas_regr = ['id_person','contract_start_date','contract_end_date','id_continuity_pf','Canal de Preferência','status','lost_time','add_time','id_label','won_time','lost_time.1','lost_reason','lost_reason.1',\\\n",
    "                     'Qde Atendimento Médico','Faltas Atendimento Médico',\t'Qde Atendimentos Acolhimento',\t'Faltas Acolhimento',\t'Qde Psicoterapia',\t'Faltas Psicoterapia','Data Última Ligações Outbound',\\\n",
    "                     'Data Última Ligações Inbound','Qde Total de Faturas Pagas após Vencimento','Qde Perfis de Pagamento Inativos', 'Valor Médio da Mensalidade', 'status_prox_mes', 'Qde Total de Faturas', 'Target','Problemas Abertos']\n",
    "\n",
    "\n",
    "colunas_get_dummies = ['id_gender','id_marrital_status','id_health_plan','notes_count','Método de Pagamento','Qde Total de Faturas Inadimpletes', 'Quem Enviou Última Mensagem']\n",
    "\n",
    "#coluna de genero\n",
    "df_total['id_gender'] = df_total['id_gender'] = df_total['id_gender'].apply(lambda x: transform_to_category(x,2,[63,64]))\n",
    "#coluna de estado civil\n",
    "#drop marrital status diferentes de 80,82,83\n",
    "df_total = df_total[df_total['id_marrital_status'].isin([80,82,83])]\n",
    "df_total['id_marrital_status'] = df_total['id_marrital_status'].apply(lambda x: transform_to_category(x,3,[80,82,83]))\n",
    "#coluna de health plan\n",
    "df_total['id_health_plan'] = df_total['id_health_plan'].apply(lambda x: transform_to_category(x,4,[412,415,418,435]))\n",
    "#coluna de notes count\n",
    "df_total = df_total[df_total['notes_count'] < 7]\n",
    "\n",
    "\n",
    "#coluna birthdate\n",
    "df_total = df_total[df_total['birthdate'].notna()]\n",
    "#coluna de fisico\n",
    "df_total['Físico'] = df_total['Físico'].fillna(df_total['Físico'].mean())\n",
    "#coluna de psicologico\n",
    "df_total['Psicológico'] = df_total['Psicológico'].fillna(df_total['Psicológico'].mean())\n",
    "#coluna de social \n",
    "df_total['Social'] = df_total['Social'].fillna(df_total['Social'].mean())\n",
    "#coluna de ambiental\n",
    "df_total['Ambiental'] = df_total['Ambiental'].fillna(df_total['Ambiental'].mean())\n",
    "#coluna de mensagens inbound\n",
    "df_total['Mensagens Inbound'] = df_total['Mensagens Inbound'].fillna(0)\n",
    "#coluna de mensagens outbound\n",
    "df_total['Mensagens Outbound'] = df_total['Mensagens Outbound'].fillna(0)\n",
    "#coluna de ligacoes inbound\n",
    "df_total['Ligações Inbound'] = df_total['Ligações Inbound'].fillna(0)\n",
    "#coluna de ligacoes outbound\n",
    "df_total['Ligações Outbound'] = df_total['Ligações Outbound'].fillna(0)\n",
    "#coluna qtd tentativas de cobrança\n",
    "df_total['Qde Total de Tentativas de Cobrança'] = df_total['Qde Total de Tentativas de Cobrança'].fillna(0)\n",
    "#coluna método de pagamento\n",
    "df_total['Método de Pagamento'] = df_total['Método de Pagamento'].apply(lambda x: transform_to_category(x,2,[\"Cartão de crédito\",\"Dinheiro\"]))\n",
    "#coluna total de faturas inadimplentes\n",
    "df_total['Qde Total de Faturas Inadimpletes'] = df_total['Qde Total de Faturas Inadimpletes'].fillna(0)\n",
    "df_total['Qde Total de Faturas Inadimpletes'] = df_total['Qde Total de Faturas Inadimpletes'].apply(lambda x: True if x > 0 else False)\n",
    "#coluna valor total inadimplente\n",
    "df_total['Valor Total Inadimplência'] = df_total['Valor Total Inadimplência'].fillna(0)\n",
    "#coluna Tempo Última Mensagem Inbound\n",
    "df_total['Tempo Última Mensagem Inbound'] = df_total['Tempo Última Mensagem Inbound'].fillna(0)\n",
    "#coluna Tempo Última Mensagem Outbound\n",
    "df_total['Tempo Última Mensagem Outbound'] = df_total['Tempo Última Mensagem Outbound'].fillna(0)\n",
    "#rename coluna birthdate para idade\n",
    "df_total = df_total.rename(columns={'birthdate':'idade'})\n",
    "# dropa linhas duplicadas\n",
    "\n",
    "df_total = df_total.drop_duplicates()\n",
    "df_regr = df_total.copy()    \n",
    "\n",
    "\n",
    "\n",
    "df_total = df_total[df_total['status'] != 'won']\n",
    "df_total = df_total.drop(colunas_dropadas, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "df_regr = pd.get_dummies(df_regr, columns=colunas_get_dummies)\n",
    "\n",
    "df_total = pd.get_dummies(df_total, columns=colunas_get_dummies)\n",
    "\n",
    "df_regr_won =  df_regr[df_regr['status'] == 'won'] # Dataframe para teste de regressão (Coerência)\n",
    "\n",
    "df_regr = df_regr[df_regr['status'] != 'won'] # Dataframe para treino de regressão \n",
    "\n",
    "\n",
    "df_regr_won['Tempo até Sair'] = df_regr_won['contract_start_date'].apply(lambda x: (pd.to_datetime('today') - pd.to_datetime(x)).days)\n",
    "\n",
    "df_regr = df_regr.drop(colunas_dropadas_regr, axis=1)\n",
    "\n",
    "df_regr_won = df_regr_won.drop(colunas_dropadas_regr, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando Decision Tree para classificar quem sai no próximo mês"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[137]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00       137\n",
      "\n",
      "    accuracy                           1.00       137\n",
      "   macro avg       1.00      1.00      1.00       137\n",
      "weighted avg       1.00      1.00      1.00       137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_total.drop('Target', axis=1), df_total['Target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the decision tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando Random Forest para classificar quem sai no próximo mês"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[137]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      1.00      1.00       137\n",
      "\n",
      "    accuracy                           1.00       137\n",
      "   macro avg       1.00      1.00      1.00       137\n",
      "weighted avg       1.00      1.00      1.00       137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_total.drop('Target', axis=1), df_total['Target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the decision tree classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pivo Modelo Regressão \n",
    "\n",
    "\n",
    "### O tratamento dos dados foi feito nos notebooks anteriores, a diferença é a utilização do tempo do cliente até o cancelamento como variável target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2438.936278260869\n",
      "Erro em dias de atraso: 49.385587758584684\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "\n",
    "y = df_regr['Tempo até Sair']\n",
    "X = df_regr.drop(['Tempo até Sair'], axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)  # Adjust test_size\n",
    "\n",
    "# Create the regression model\n",
    "model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Erro em dias de atraso:\", np.sqrt(mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste de Coerência\n",
    "\n",
    "#### Aqui realizamos um teste para verificar se o modelo está coerente com a realidade.\n",
    "\n",
    "#### Para isso, utilizamos o dataset de pessoas que ainda estão ativas para tentar entender o comportamento do modelo ao prever o tempo de cancelamento e comparar com o tempo real que a pessoa está ativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 11862.394181586094\n",
      "Erro em dias de atraso: 108.91461876895174\n",
      "Erro médio: -82.33510592069527\n"
     ]
    }
   ],
   "source": [
    "# Usando os dados de clientes que ainda estão para comparar com os dados de clientes que sairam apenas para testar o modelo\n",
    "y = df_regr_won['Tempo até Sair']\n",
    "X = df_regr_won.drop(['Tempo até Sair'], axis=1)\n",
    "# Make predictions on the testing set\n",
    "y_pred = model.predict(X)\n",
    "# Evaluate the performance of the model\n",
    "mse = mean_squared_error(y, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Erro em dias de atraso:\", np.sqrt(mse))\n",
    "\n",
    "# Verificar se está errando para mais ou para menos\n",
    "print('Erro médio:', np.mean(y_pred - y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
