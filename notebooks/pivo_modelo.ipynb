{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivô\n",
    "### Modelo de classificação para verificar a se um cliente vai ou não cancelar o serviço no próximo mês\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo os dados temporais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agosto = pd.read_csv('../data/Agosto/Ana Health_Tabela Modelo Previsão Churn - Tabela até 08_23.csv', skiprows=1)\n",
    "df_julho = pd.read_csv('../data/Julho/Ana Health_Tabela Modelo Previsão Churn - Tabela até 07_23.csv', skiprows=1)\n",
    "df_junho = pd.read_csv('../data/Junho/Ana Health_Tabela Modelo Previsão Churn - Tabela até 06_23.csv', skiprows=1)\n",
    "df_novembro = pd.read_csv('../data/Novembro/Ana Health_Tabela Modelo Previsão Churn - Tabela Geral.csv', skiprows=1)\n",
    "df_outubro = pd.read_csv('../data/Outubro/Ana Health_Tabela Modelo Previsão Churn - Tabela até 10_23.csv', skiprows=1)\n",
    "df_setembro = pd.read_csv('../data/Setembro/Ana Health_Tabela Modelo Previsão Churn - Tabela até 09_23.csv', skiprows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fazendo o tratamento de cada um dos datasets via script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import script_dataframe\n",
    "import importlib\n",
    "\n",
    "importlib.reload(script_dataframe)\n",
    "tratamento = script_dataframe.tratamento\n",
    "\n",
    "df_agosto = tratamento(df_agosto)\n",
    "df_julho = tratamento(df_julho)\n",
    "df_junho = tratamento(df_junho)\n",
    "df_novembro = tratamento(df_novembro)\n",
    "df_outubro = tratamento(df_outubro)\n",
    "df_setembro = tratamento(df_setembro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definindo a função para, dado um mês, retornar o dataset do mês seguinte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prox_status(df1, df2):\n",
    "    df2_novo = df2[df2['id_person'].isin(df1['id_person'].values)]\n",
    "    return pd.merge(df1,df2_novo[['id_person','status']],on='id_person', how='left',suffixes=['','_prox_mes'])\n",
    "\n",
    "df_junho = prox_status(df_junho, df_julho)\n",
    "df_julho = prox_status(df_julho, df_agosto)\n",
    "df_agosto = prox_status(df_agosto, df_setembro)\n",
    "df_setembro = prox_status(df_setembro, df_outubro)\n",
    "df_outubro  = prox_status(df_outubro, df_novembro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenando os datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 4680 entries, 0 to 1022\n",
      "Data columns (total 54 columns):\n",
      " #   Column                                      Non-Null Count  Dtype         \n",
      "---  ------                                      --------------  -----         \n",
      " 0   id_person                                   4680 non-null   int64         \n",
      " 1   birthdate                                   4675 non-null   float64       \n",
      " 2   id_gender                                   4662 non-null   float64       \n",
      " 3   id_marrital_status                          4670 non-null   float64       \n",
      " 4   id_health_plan                              2204 non-null   float64       \n",
      " 5   contract_start_date                         4680 non-null   datetime64[ns]\n",
      " 6   contract_end_date                           2292 non-null   datetime64[ns]\n",
      " 7   id_continuity_pf                            1687 non-null   float64       \n",
      " 8   Canal de Preferência                        1473 non-null   float64       \n",
      " 9   notes_count                                 4680 non-null   int64         \n",
      " 10  done_activities_count                       4680 non-null   int64         \n",
      " 11  status                                      4680 non-null   object        \n",
      " 12  start_of_service                            4680 non-null   float64       \n",
      " 13  lost_time                                   2169 non-null   float64       \n",
      " 14  lost_reason                                 2292 non-null   object        \n",
      " 15  add_time                                    4502 non-null   float64       \n",
      " 16  id_label                                    389 non-null    float64       \n",
      " 17  won_time                                    2890 non-null   float64       \n",
      " 18  lost_time.1                                 1293 non-null   float64       \n",
      " 19  lost_reason.1                               1293 non-null   object        \n",
      " 20  Qde Todos Atendimentos                      4680 non-null   int64         \n",
      " 21  Faltas Todos Atendimento                    4680 non-null   int64         \n",
      " 22  Qde Atendimento Médico                      801 non-null    float64       \n",
      " 23  Faltas Atendimento Médico                   801 non-null    float64       \n",
      " 24  Qde Atendimentos Acolhimento                2744 non-null   float64       \n",
      " 25  Faltas Acolhimento                          2744 non-null   float64       \n",
      " 26  Qde Psicoterapia                            1797 non-null   float64       \n",
      " 27  Faltas Psicoterapia                         587 non-null    object        \n",
      " 28  Físico                                      3562 non-null   float64       \n",
      " 29  Psicológico                                 3562 non-null   float64       \n",
      " 30  Social                                      3562 non-null   float64       \n",
      " 31  Ambiental                                   3562 non-null   float64       \n",
      " 32  Problemas Abertos                           2402 non-null   object        \n",
      " 33  Mensagens Inbound                           4367 non-null   float64       \n",
      " 34  Mensagens Outbound                          4606 non-null   float64       \n",
      " 35  Ligações Inbound                            430 non-null    float64       \n",
      " 36  Data Última Ligações Inbound                430 non-null    object        \n",
      " 37  Ligações Outbound                           2271 non-null   float64       \n",
      " 38  Data Última Ligações Outbound               2271 non-null   object        \n",
      " 39  Qde Total de Faturas                        880 non-null    float64       \n",
      " 40  Qde Total de Tentativas de Cobrança         878 non-null    float64       \n",
      " 41  Método de Pagamento                         880 non-null    object        \n",
      " 42  Valor Médio da Mensalidade                  880 non-null    float64       \n",
      " 43  Qde Total de Faturas Pagas após Vencimento  880 non-null    float64       \n",
      " 44  Qde Total de Faturas Inadimpletes           880 non-null    float64       \n",
      " 45  Valor Total Inadimplência                   880 non-null    float64       \n",
      " 46  Qde Perfis de Pagamento Inativos            0 non-null      float64       \n",
      " 47  Tempo até Sair                              2292 non-null   float64       \n",
      " 48  Tem Problema em Aberto                      4680 non-null   int64         \n",
      " 49  Tempo Última Mensagem Inbound               4367 non-null   float64       \n",
      " 50  Tempo Última Mensagem Outbound              4606 non-null   float64       \n",
      " 51  Quem Enviou Última Mensagem                 4680 non-null   object        \n",
      " 52  status_prox_mes                             4680 non-null   object        \n",
      " 53  Target                                      4680 non-null   bool          \n",
      "dtypes: bool(1), datetime64[ns](2), float64(35), int64(6), object(10)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_total = pd.concat([df_junho, df_julho, df_agosto, df_setembro, df_outubro])\n",
    "\n",
    "df_total['Target'] = df_total['status_prox_mes'] == 'won'\n",
    "\n",
    "df_total['Target'].value_counts()\n",
    "df_total.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando DataFrames - \n",
    "\n",
    "Temos dois dataframes que pretendemos utilizar. O primeiro, e principal, é referente a análise de quem sai no próximo mës. O segundo, é uma tentativa de prever quanto tempo até o usuário sair. \n",
    "\n",
    "### DataSet 1 - Saída de Clientes no Próximo Mës \n",
    "- Nele, temos uma coluna de ***target*** que é binária (valores verdadeiros indicam que a pessoa saiu no próxima mës). As colunas que contemplamos tem relação com o perfil do cliente, como idade, sexo, estado civil, etc. A maioria dos dados já passaram pelo script_dataframe (e a função `tratamento`) para adição de colunas novas, tratamento de datas e criação de dummies.\n",
    "\n",
    "### DataSet 2 - Tempo até o Cliente Sair\n",
    "- Processo de criação foi parecida com o anterior, mas aqui temos uma coluna de ***target*** que é contínua (valores indicam quantos dias até o cliente sair). As colunas que contemplamos tem relação com o perfil do cliente, como idade, sexo, estado civil, etc. A maioria dos dados já passaram pelo script_dataframe (e a função `tratamento`) para adição de colunas novas, tratamento de datas e criação de dummies. A diferença é que contemplamos a colunas de faltas de atendimentos e consultas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_category(x,qtd_itens,lista_itens):\n",
    "   for i in range(qtd_itens):\n",
    "      if x == lista_itens[i]:\n",
    "         return str(x)\n",
    "   return 'Outros'\n",
    "   \n",
    "colunas = df_total.columns\n",
    "colunas_dropadas = ['id_person','contract_start_date','contract_end_date','id_continuity_pf','Canal de Preferência','status','lost_time','add_time','id_label','won_time','lost_time.1','lost_reason','lost_reason.1',\\\n",
    "                    'Qde Atendimento Médico','Faltas Atendimento Médico',\t'Qde Atendimentos Acolhimento',\t'Faltas Acolhimento',\t'Qde Psicoterapia',\t'Faltas Psicoterapia','Data Última Ligações Outbound',\\\n",
    "                     'Data Última Ligações Inbound','Qde Total de Faturas Pagas após Vencimento','Qde Perfis de Pagamento Inativos','Tempo até Sair', 'Valor Médio da Mensalidade', 'status_prox_mes', 'Qde Total de Faturas','Problemas Abertos']\n",
    "\n",
    "colunas_get_dummies = ['id_gender','id_marrital_status','id_health_plan','notes_count','Método de Pagamento','Qde Total de Faturas Inadimpletes', 'Quem Enviou Última Mensagem']\n",
    "\n",
    "#coluna de genero\n",
    "df_total['id_gender'] = df_total['id_gender'] = df_total['id_gender'].apply(lambda x: transform_to_category(x,2,[63,64]))\n",
    "#coluna de estado civil\n",
    "#drop marrital status diferentes de 80,82,83\n",
    "df_total = df_total[df_total['id_marrital_status'].isin([80,82,83])]\n",
    "df_total['id_marrital_status'] = df_total['id_marrital_status'].apply(lambda x: transform_to_category(x,3,[80,82,83]))\n",
    "#coluna de health plan\n",
    "df_total['id_health_plan'] = df_total['id_health_plan'].apply(lambda x: transform_to_category(x,4,[412,415,418,435]))\n",
    "#coluna de notes count\n",
    "df_total = df_total[df_total['notes_count'] < 7]\n",
    "\n",
    "\n",
    "#coluna birthdate\n",
    "df_total = df_total[df_total['birthdate'].notna()]\n",
    "#coluna de fisico\n",
    "df_total['Físico'] = df_total['Físico'].fillna(df_total['Físico'].mean())\n",
    "#coluna de psicologico\n",
    "df_total['Psicológico'] = df_total['Psicológico'].fillna(df_total['Psicológico'].mean())\n",
    "#coluna de social \n",
    "df_total['Social'] = df_total['Social'].fillna(df_total['Social'].mean())\n",
    "#coluna de ambiental\n",
    "df_total['Ambiental'] = df_total['Ambiental'].fillna(df_total['Ambiental'].mean())\n",
    "#coluna de mensagens inbound\n",
    "df_total['Mensagens Inbound'] = df_total['Mensagens Inbound'].fillna(0)\n",
    "#coluna de mensagens outbound\n",
    "df_total['Mensagens Outbound'] = df_total['Mensagens Outbound'].fillna(0)\n",
    "#coluna de ligacoes inbound\n",
    "df_total['Ligações Inbound'] = df_total['Ligações Inbound'].fillna(0)\n",
    "#coluna de ligacoes outbound\n",
    "df_total['Ligações Outbound'] = df_total['Ligações Outbound'].fillna(0)\n",
    "#coluna qtd tentativas de cobrança\n",
    "df_total['Qde Total de Tentativas de Cobrança'] = df_total['Qde Total de Tentativas de Cobrança'].fillna(0)\n",
    "#coluna método de pagamento\n",
    "df_total['Método de Pagamento'] = df_total['Método de Pagamento'].apply(lambda x: transform_to_category(x,2,[\"Cartão de crédito\",\"Dinheiro\"]))\n",
    "#coluna total de faturas inadimplentes\n",
    "df_total['Qde Total de Faturas Inadimpletes'] = df_total['Qde Total de Faturas Inadimpletes'].fillna(0)\n",
    "df_total['Qde Total de Faturas Inadimpletes'] = df_total['Qde Total de Faturas Inadimpletes'].apply(lambda x: True if x > 0 else False)\n",
    "#coluna valor total inadimplente\n",
    "df_total['Valor Total Inadimplência'] = df_total['Valor Total Inadimplência'].fillna(0)\n",
    "#coluna Tempo Última Mensagem Inbound\n",
    "df_total['Tempo Última Mensagem Inbound'] = df_total['Tempo Última Mensagem Inbound'].fillna(0)\n",
    "#coluna Tempo Última Mensagem Outbound\n",
    "df_total['Tempo Última Mensagem Outbound'] = df_total['Tempo Última Mensagem Outbound'].fillna(0)\n",
    "#rename coluna birthdate para idade\n",
    "df_total = df_total.rename(columns={'birthdate':'idade'})\n",
    "# dropa linhas duplicadas\n",
    "\n",
    "df_total = df_total.drop_duplicates()\n",
    "df_total = df_total[df_total['status'] != 'lost']\n",
    "df_total = df_total.drop(colunas_dropadas, axis=1)\n",
    "df_total = pd.get_dummies(df_total, columns=colunas_get_dummies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\code\\Desktop\\sprint4\\sprint4-ana-coda\\notebooks\\pivo_modelo.ipynb Célula 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/code/Desktop/sprint4/sprint4-ana-coda/notebooks/pivo_modelo.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m clf \u001b[39m=\u001b[39m LogisticRegression(random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/code/Desktop/sprint4/sprint4-ana-coda/notebooks/pivo_modelo.ipynb#X22sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/code/Desktop/sprint4/sprint4-ana-coda/notebooks/pivo_modelo.ipynb#X22sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m clf\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/code/Desktop/sprint4/sprint4-ana-coda/notebooks/pivo_modelo.ipynb#X22sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# Make predictions on the test set\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/code/Desktop/sprint4/sprint4-ana-coda/notebooks/pivo_modelo.ipynb#X22sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m y_pred \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\code\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\code\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1252\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1250\u001b[0m classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\n\u001b[0;32m   1251\u001b[0m \u001b[39mif\u001b[39;00m n_classes \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m-> 1252\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1253\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThis solver needs samples of at least 2 classes\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1254\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m in the data, but the data contains only one\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1255\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m class: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1256\u001b[0m         \u001b[39m%\u001b[39m classes_[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1257\u001b[0m     )\n\u001b[0;32m   1259\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m   1260\u001b[0m     n_classes \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: True"
     ]
    }
   ],
   "source": [
    "#decision tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_total.drop('Target', axis=1), df_total['Target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the decision tree classifier\n",
    "clf = LogisticRegression(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[369]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       1.00      1.00      1.00       369\n",
      "\n",
      "    accuracy                           1.00       369\n",
      "   macro avg       1.00      1.00      1.00       369\n",
      "weighted avg       1.00      1.00      1.00       369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_total.drop('Target', axis=1), df_total['Target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the decision tree classifier\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      "[[369]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        True       1.00      1.00      1.00       369\n",
      "\n",
      "    accuracy                           1.00       369\n",
      "   macro avg       1.00      1.00      1.00       369\n",
      "weighted avg       1.00      1.00      1.00       369\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_total.drop('Target', axis=1), df_total['Target'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the decision tree classifier\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_mat)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
